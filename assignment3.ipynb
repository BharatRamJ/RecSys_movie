{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 by: Bharatram Jeyaraman (s4026884)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: User-based Collaborative Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse.linalg import svds\n",
    "import networkx as nx\n",
    "from sklearn.metrics import average_precision_score, ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.dat file path: c:\\Bharat_2023\\Practical_datascience_with_python\\Assignment3\\ml-1m\\movies.dat\n",
      "ratings.dat file path: c:\\Bharat_2023\\Practical_datascience_with_python\\Assignment3\\ml-1m\\ratings.dat\n",
      "users.dat file path: c:\\Bharat_2023\\Practical_datascience_with_python\\Assignment3\\ml-1m\\users.dat\n"
     ]
    }
   ],
   "source": [
    "# Directory where the data files are located\n",
    "data_directory = 'ml-1m'\n",
    "\n",
    "# Define a dictionary to store file names and corresponding column names\n",
    "file_info = {\n",
    "    'movies.dat': ['MovieID', 'Title', 'Genres'],\n",
    "    'ratings.dat': ['UserID', 'MovieID', 'Rating', 'Timestamp'],\n",
    "    'users.dat': ['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code']\n",
    "}\n",
    "\n",
    "# Create a dictionary to store data frames\n",
    "data_frames = {}\n",
    "\n",
    "# Get the absolute file paths and load the data into data frames\n",
    "for file_name, column_names in file_info.items():\n",
    "    file_path = os.path.abspath(os.path.join(data_directory, file_name))\n",
    "    data_frames[file_name] = pd.read_csv(file_path, sep='::', names=column_names, engine='python', encoding='iso-8859-1')\n",
    "\n",
    "# Print file paths\n",
    "for file_name, file_path in data_frames.items():\n",
    "    print(f\"{file_name} file path: {os.path.abspath(os.path.join(data_directory, file_name))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing data frames \n",
    "movies_df = data_frames['movies.dat']\n",
    "ratings_df = data_frames['ratings.dat']\n",
    "users_df = data_frames['users.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3883, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000209, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the task of building a recommendation model based on calculations for user-user similarities, we need only the ratings_df dataframe as it contains all the essential information about the user-item interactions like userid, movieid and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040\n"
     ]
    }
   ],
   "source": [
    "unique_userid = len(ratings_df['UserID'].unique())\n",
    "print(unique_userid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have 6040 unique users whose ID value ranges from 0 to 6040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706\n"
     ]
    }
   ],
   "source": [
    "unique_movieid = len(ratings_df['MovieID'].unique())\n",
    "print(unique_movieid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 3706 unique movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000209\n"
     ]
    }
   ],
   "source": [
    "total_number_of_ratings = ratings_df.shape[0]\n",
    "print(total_number_of_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_rating = 6040 * 3706 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.468362562231285\n"
     ]
    }
   ],
   "source": [
    "rating_percentage = (total_number_of_ratings / possible_rating) * 100\n",
    "print(rating_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating_percentage shows that only 4.468% of data will be present in the utility matrix for the given number of ratings in ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum rating\n",
    "ratings_df['Rating'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum rating\n",
    "ratings_df['Rating'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly splitting the dataset into train (80%) and test (20%)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an user-item matrix\n",
    "n_users = max(users_df['UserID'])\n",
    "n_items = max(movies_df['MovieID'])\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "train_data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the user-item matrix with ratings\n",
    "for row in train_df.itertuples():\n",
    "    train_data_matrix[row[1] - 1, row[2] - 1] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random user from the ratings dataset\n",
    "unique_user_ids = train_df['UserID'].unique()\n",
    "random_user_id = random.choice(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1298"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating user similarity using cosine similarity\n",
    "user_similarity = 1 - pairwise_distances(train_data_matrix, train_data_matrix, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_recommendations(user_id, similarity_matrix, k):\n",
    "    # Finding the top-k most similar users to the target user\n",
    "    similar_users = np.argsort(similarity_matrix[user_id - 1])[::-1][1:k + 1]\n",
    "\n",
    "    # Initializing arrays to store weighted sum and similarity sum for each item\n",
    "    weighted_sums = np.zeros(n_items)\n",
    "    similarity_sums = np.zeros(n_items)\n",
    "\n",
    "    # Getting the user's rated items and their ratings\n",
    "    user_ratings = train_data_matrix[user_id - 1]\n",
    "    rated_items = user_ratings.nonzero()[0]\n",
    "\n",
    "    # Calculating predictions for unrated items\n",
    "    for neighbor_id in similar_users:\n",
    "        neighbor_ratings = train_data_matrix[neighbor_id]\n",
    "        for item_id in range(n_items):\n",
    "            if item_id not in rated_items:\n",
    "                neighbor_rating = neighbor_ratings[item_id]\n",
    "                if neighbor_rating > 0:\n",
    "                    similarity = similarity_matrix[user_id - 1][neighbor_id]\n",
    "                    weighted_sums[item_id] += similarity * neighbor_rating\n",
    "                    similarity_sums[item_id] += abs(similarity)\n",
    "\n",
    "    # Calculating predictions for each item\n",
    "    pred_ratings = np.zeros(n_items)\n",
    "    for item_id in range(n_items):\n",
    "        if item_id not in rated_items and similarity_sums[item_id] > 0:\n",
    "            pred_ratings[item_id] = weighted_sums[item_id] / similarity_sums[item_id]\n",
    "\n",
    "    return pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_matrix shape: (6040, 3952)\n",
      "user_similarity shape: (6040, 6040)\n",
      "user_recommendations shape: (3952,)\n"
     ]
    }
   ],
   "source": [
    "# Verifying the dimensions of the user-item matrix and user similarity matrix\n",
    "print(\"train_data_matrix shape:\", train_data_matrix.shape)\n",
    "print(\"user_similarity shape:\", user_similarity.shape)\n",
    "\n",
    "# Calculating recommendations for the random user\n",
    "user_recommendations = user_based_recommendations(random_user_id, user_similarity, 20)\n",
    "\n",
    "print(\"user_recommendations shape:\", user_recommendations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_value=15, MAE=0.81, RMSE=1.12\n",
      "k_value=50, MAE=0.60, RMSE=0.69\n",
      "k_value=100, MAE=0.61, RMSE=0.73\n",
      "k_value=150, MAE=0.59, RMSE=0.70\n",
      "k_value=500, MAE=0.59, RMSE=0.70\n"
     ]
    }
   ],
   "source": [
    "def calculate_mae_rmse(user_similarity, k_values):\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "\n",
    "    for k in k_values:\n",
    "        predicted_ratings = user_based_recommendations(random_user_id, user_similarity, k)\n",
    "        \n",
    "        # Extract the true ratings for the test user\n",
    "        true_ratings = []\n",
    "        for row in test_df.itertuples():\n",
    "            if row[1] == random_user_id:\n",
    "                true_ratings.append((row[2], row[3]))\n",
    "\n",
    "        # Calculate MAE and RMSE\n",
    "        predicted = [predicted_ratings[item_id - 1] for item_id, _ in true_ratings]\n",
    "        true = [rating for _, rating in true_ratings]\n",
    "\n",
    "        mae = mean_absolute_error(true, predicted)\n",
    "        rmse = math.sqrt(mean_squared_error(true, predicted))\n",
    "\n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "        print(f\"k_value={k}, MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
    "\n",
    "    return mae_scores, rmse_scores\n",
    "\n",
    "# Define a list of k values to evaluate\n",
    "k_values_to_evaluate = [15, 50, 100, 150, 500]\n",
    "\n",
    "mae_scores, rmse_scores = calculate_mae_rmse(user_similarity, k_values_to_evaluate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10  # Number of recommendations\n",
    "top_N_indices = np.argsort(user_recommendations)[::-1][:N]\n",
    "recommended_movies = top_N_indices + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2512 1564 2721 3822  308 1925 1260 1224 2056 2068]\n"
     ]
    }
   ],
   "source": [
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ballad of Narayama, The (Narayama Bushiko) (1982)', \"Roseanna's Grave (For Roseanna) (1997)\", 'Trick (1999)', 'Girl on the Bridge, The (La Fille sur le Pont) (1999)', 'Three Colors: White (1994)', 'Wings (1927)', 'M (1931)', 'Henry V (1989)', 'In Search of the Castaways (1962)', 'Fanny and Alexander (1982)']\n"
     ]
    }
   ],
   "source": [
    "movie_id_name = dict(zip(movies_df['MovieID'], movies_df['Title']))\n",
    "recommended_movie_names = [movie_id_name[movie_id] for movie_id in recommended_movies]\n",
    "print(recommended_movie_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Item-based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_cosine = 1 - pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "item_similarity_pearson = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommendations(movie_id, similarity_matrix, k):\n",
    "    # Find the top-k most similar items to the target movie\n",
    "    similar_items = np.argsort(similarity_matrix[movie_id - 1])[::-1][1:k + 1]\n",
    "\n",
    "    # Initialize arrays to store weighted sum and similarity sum for each user\n",
    "    weighted_sums = np.zeros(n_users)\n",
    "    similarity_sums = np.zeros(n_users)\n",
    "\n",
    "    # Get the movie's ratings\n",
    "    movie_ratings = train_data_matrix.T[movie_id - 1]\n",
    "    rated_users = movie_ratings.nonzero()[0]\n",
    "\n",
    "    # Calculate predictions for unrated users\n",
    "    for similar_movie_id in similar_items:\n",
    "        similar_movie_ratings = train_data_matrix.T[similar_movie_id]\n",
    "        for user_id in range(n_users):\n",
    "            if user_id not in rated_users:\n",
    "                similar_movie_rating = similar_movie_ratings[user_id]\n",
    "                if similar_movie_rating > 0:\n",
    "                    similarity = similarity_matrix[movie_id - 1][similar_movie_id]\n",
    "                    weighted_sums[user_id] += similarity * similar_movie_rating\n",
    "                    similarity_sums[user_id] += abs(similarity)\n",
    "\n",
    "    # Calculate predictions for each user\n",
    "    pred_ratings = np.zeros(n_users)\n",
    "    for user_id in range(n_users):\n",
    "        if user_id not in rated_users and similarity_sums[user_id] > 0:\n",
    "            pred_ratings[user_id] = weighted_sums[user_id] / similarity_sums[user_id]\n",
    "\n",
    "    return pred_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_item_based_recommender(movie_id, cosine_similarity_matrix, pearson_similarity_matrix, k_values):\n",
    "    rmse_scores_cosine = []\n",
    "    mae_scores_cosine = []\n",
    "    rmse_scores_pearson = []\n",
    "    mae_scores_pearson = []\n",
    "\n",
    "    for k in k_values:\n",
    "        # Predict ratings using cosine similarity\n",
    "        predicted_ratings_cosine = item_based_recommendations(movie_id, cosine_similarity_matrix, k)\n",
    "\n",
    "        # Predict ratings using Pearson correlation coefficient\n",
    "        predicted_ratings_pearson = item_based_recommendations(movie_id, pearson_similarity_matrix, k)\n",
    "\n",
    "        # Extract the true ratings for the test user\n",
    "        true_ratings = []\n",
    "        for row in test_df.itertuples():\n",
    "            if row[2] == movie_id:\n",
    "                true_ratings.append((row[1], row[3]))\n",
    "\n",
    "        # Calculate MAE and RMSE for both similarity metrics\n",
    "        true = [rating for _, rating in true_ratings]\n",
    "        predicted_cosine = [predicted_ratings_cosine[user_id - 1] for user_id, _ in true_ratings]\n",
    "        predicted_pearson = [predicted_ratings_pearson[user_id - 1] for user_id, _ in true_ratings]\n",
    "\n",
    "        rmse_cosine = sqrt(mean_squared_error(true, predicted_cosine))\n",
    "        mae_cosine = mean_absolute_error(true, predicted_cosine)\n",
    "        rmse_pearson = sqrt(mean_squared_error(true, predicted_pearson))\n",
    "        mae_pearson = mean_absolute_error(true, predicted_pearson)\n",
    "\n",
    "        rmse_scores_cosine.append(rmse_cosine)\n",
    "        mae_scores_cosine.append(mae_cosine)\n",
    "        rmse_scores_pearson.append(rmse_pearson)\n",
    "        mae_scores_pearson.append(mae_pearson)\n",
    "\n",
    "    return rmse_scores_cosine, mae_scores_cosine, rmse_scores_pearson, mae_scores_pearson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_movie_id = np.random.choice(movies_df['MovieID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings exist for Movie 2901 in the test data.\n"
     ]
    }
   ],
   "source": [
    "if random_movie_id in test_df['MovieID'].unique():\n",
    "    print(f\"Ratings exist for Movie {random_movie_id} in the test data.\")\n",
    "else:\n",
    "    print(f\"No ratings found for Movie {random_movie_id} in the test data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        UserID  MovieID  Rating   Timestamp\n",
      "233492    1420     2901       2   974759893\n",
      "462285    2852     2901       5   972507094\n",
      "162996    1040     2901       4   974981376\n",
      "525918    3249     2901       2   968298394\n",
      "513748    3169     2901       1   968809814\n",
      "297916    1765     2901       4   974706689\n",
      "708192    4245     2901       2   965309151\n",
      "394288    2323     2901       3   975980885\n",
      "138761     889     2901       2   975249060\n",
      "40477      272     2901       3   976694447\n",
      "490940    3018     2901       3   982706697\n",
      "348524    2042     2901       4   974666877\n",
      "633571    3824     2901       4   970245863\n",
      "339584    2001     2901       5   974685751\n",
      "581432    3550     2901       4   967000069\n",
      "605029    3678     2901       3   967053917\n",
      "642106    3860     2901       3   965860136\n",
      "108274     710     2901       3   978376283\n",
      "102581     678     2901       3   989501470\n",
      "374380    2181     2901       4   974609613\n",
      "957352    5778     2901       4   958158108\n",
      "780067    4658     2901       1   963878767\n",
      "344478    2021     2901       2   974673144\n",
      "549235    3389     2901       3   967514850\n",
      "165340    1053     2901       2   974952648\n",
      "718158    4303     2901       4   965269389\n",
      "628407    3806     2901       3   965965882\n",
      "960658    5794     2901       3   958068769\n",
      "458247    2820     2901       3   972658293\n",
      "892154    5389     2901       2   960328180\n",
      "234329    1422     2901       2   976139469\n",
      "260720    1593     2901       3  1014180878\n",
      "307675    1835     2901       4   974878592\n",
      "690615    4132     2901       3   965350821\n",
      "830300    4985     2901       4   962593275\n",
      "745055    4448     2901       5   965135293\n",
      "844520    5075     2901       5   962422114\n",
      "688889    4121     2901       3   965357450\n",
      "628823    3807     2901       5   965966217\n",
      "627975    3801     2901       4   965998154\n",
      "828271    4977     2901       3   962601671\n",
      "672891    4041     2901       5   965513837\n",
      "591304    3607     2901       1   971915807\n",
      "409777    2457     2901       3   974180236\n",
      "614937    3724     2901       3   966226547\n",
      "666522    4011     2901       2   965543240\n",
      "451850    2781     2901       4  1011020995\n",
      "97184      651     2901       2   975708922\n",
      "900196    5443     2901       4   959980390\n",
      "852305    5112     2901       2   962326503\n",
      "969755    5845     2901       5   957799167\n",
      "577790    3528     2901       2   966900555\n",
      "665527    4006     2901       3   965550685\n",
      "584834    3569     2901       3   969667141\n",
      "982465    5929     2901       2   957249196\n",
      "880515    5319     2901       4   960865052\n",
      "341982    2013     2901       2   974676232\n",
      "962393    5800     2901       2   958015152\n",
      "356544    2088     2901       3   974655677\n",
      "666376    4009     2901       1   965958216\n"
     ]
    }
   ],
   "source": [
    "movie_ratings = test_df[test_df['MovieID'] == random_movie_id]\n",
    "print(movie_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity:\n",
      "K=5, MAE=1.54, RMSE=2.01\n",
      "K=15, MAE=1.02, RMSE=1.36\n",
      "K=25, MAE=0.94, RMSE=1.21\n",
      "K=50, MAE=0.86, RMSE=1.07\n",
      "Pearson Correlation:\n",
      "K=5, MAE=3.08, RMSE=3.27\n",
      "K=15, MAE=3.08, RMSE=3.27\n",
      "K=25, MAE=3.08, RMSE=3.27\n",
      "K=50, MAE=3.08, RMSE=3.27\n"
     ]
    }
   ],
   "source": [
    "# Define a list of k values to evaluate\n",
    "k_values_to_evaluate = [5, 15, 25, 50]\n",
    "\n",
    "# Call the function to evaluate the item-based recommender\n",
    "rmse_scores_cosine, mae_scores_cosine, rmse_scores_pearson, mae_scores_pearson  = evaluate_item_based_recommender(random_movie_id, item_similarity_cosine, item_similarity_pearson, k_values_to_evaluate)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cosine Similarity:\")\n",
    "for k, rmse, mae in zip(k_values_to_evaluate, rmse_scores_cosine, mae_scores_cosine):\n",
    "    print(f\"K={k}, MAE={mae:.2f}, RMSE={rmse:.2f}\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Pearson Correlation:\")\n",
    "for k, rmse, mae in zip(k_values_to_evaluate, rmse_scores_pearson, mae_scores_pearson):\n",
    "    print(f\"K={k}, MAE={mae:.2f}, RMSE={rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: A Better Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  MovieID  Rating  Timestamp\n",
       "0             1     1193       5  978300760\n",
       "1             1      661       3  978302109\n",
       "2             1      914       3  978301968\n",
       "3             1     3408       4  978300275\n",
       "4             1     2355       5  978824291\n",
       "...         ...      ...     ...        ...\n",
       "1000204    6040     1091       1  956716541\n",
       "1000205    6040     1094       5  956704887\n",
       "1000206    6040      562       5  956704746\n",
       "1000207    6040     1096       4  956715648\n",
       "1000208    6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the user-item matrix\n",
    "user_item_matrix = ratings_df.pivot(index='UserID', columns='MovieID', values='Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity of the user-item matrix: 95.53%\n"
     ]
    }
   ],
   "source": [
    "# calculating the sparsity of the matrix \n",
    "total_entries = user_item_matrix.size\n",
    "missing_entries = user_item_matrix.isnull().sum().sum()\n",
    "matrix_sparsity = (missing_entries / total_entries) * 100\n",
    "\n",
    "print(f\"sparsity of the user-item matrix: {matrix_sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of factors for matrix factorization\n",
    "num_factors = 50\n",
    "\n",
    "# Perform SVD on the user-item matrix (train_data_matrix)\n",
    "U, sigma, Vt = svds(train_data_matrix, k=num_factors)\n",
    "\n",
    "# Convert sigma to a diagonal matrix\n",
    "sigma_diag = np.diag(sigma)\n",
    "\n",
    "# Predict missing ratings using the derived matrices\n",
    "predicted_ratings = np.dot(np.dot(U, sigma_diag), Vt)\n",
    "\n",
    "# Calculate the average rating (mu)\n",
    "mu = np.mean(train_data_matrix[train_data_matrix > 0])\n",
    "\n",
    "# Calculate user bias (bu) and item bias (bi)\n",
    "bu = np.zeros(n_users)\n",
    "bi = np.zeros(n_items)\n",
    "\n",
    "for i in range(n_users):\n",
    "    user_ratings = train_data_matrix[i, :]\n",
    "    rated_items = user_ratings.nonzero()[0]\n",
    "    bu[i] = np.sum(user_ratings - mu) / (1 + len(rated_items))\n",
    "\n",
    "for j in range(n_items):\n",
    "    item_ratings = train_data_matrix[:, j]\n",
    "    rated_users = item_ratings.nonzero()[0]\n",
    "    bi[j] = np.sum(item_ratings - mu) / (1 + len(rated_users))\n",
    "\n",
    "# Predict missing ratings with bias correction\n",
    "predicted_ratings += mu + bu[:, np.newaxis] + bi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the user similarity using the user-factor matrix U obtained by SVD\n",
    "user_similarity_matrix = 1 - pairwise_distances(U, metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top-k most similar items to the target movie\n",
    "def top_k_similar_users(user_id, user_similarity, k):\n",
    "    similar_users = np.argsort(user_similarity[user_id - 1])[::-1][1:k + 1]\n",
    "    return similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 similar users to User 5: [5046 4792 1280 1844 2944 5433 5791 3523 2529 2237 2050 3720 3093 1635\n",
      " 4138  951 2862 1582 4573  817]\n"
     ]
    }
   ],
   "source": [
    "target_user_id = 5\n",
    "k_value = 20\n",
    "similar_users = top_k_similar_users(target_user_id, user_similarity_matrix, k_value)\n",
    "print(f\"Top-{k_value} similar users to User {target_user_id}: {similar_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a directed graph for PageRank\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining transition matrix based on the user similarity\n",
    "for user_id in range(1, n_users + 1):\n",
    "    similar_users = top_k_similar_users(user_id, user_similarity_matrix, k = 500)\n",
    "    for similar_user in similar_users:\n",
    "        G.add_edge(user_id, similar_user)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying pageRank to calculate the user importance scores\n",
    "pagerank_scores = nx.pagerank(G, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the item ratings from the ratings dataframe\n",
    "def get_item_rating(item_id):\n",
    "    item_ratings = ratings_df[ratings_df['MovieID'] == item_id]['Rating']\n",
    "    if(len(item_ratings)) > 0:\n",
    "        average_rating = item_ratings.mean()\n",
    "    else:\n",
    "        average_rating = 0.0\n",
    "    return average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the item rankings and calculating weight point rank\n",
    "item_ratings = {}\n",
    "for item_id in range(1, n_items + 1):\n",
    "    item_ratings[item_id] = get_item_rating(item_id)\n",
    "\n",
    "# setting the weights for pageRank and item ratings\n",
    "alpha = 0.8 # pageRank score weight\n",
    "beta = 0.2 # item ratings score weight\n",
    "\n",
    "# calculating weight point rank\n",
    "weight_point_rank = {}\n",
    "for item_id, pagerank_score in enumerate(item_ratings, 1):\n",
    "    item_rating = item_ratings[item_id]\n",
    "\n",
    "    weight_point_rank[item_id] = alpha * pagerank_score + beta * item_rating\n",
    "\n",
    "sorted_items = sorted(weight_point_rank.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations_SVD_WPR(n_users, n_items, n_recommendations):\n",
    "    recommendations = {}\n",
    "    for user_id in range(1, n_users + 1):\n",
    "        recommended_items = np.random.choice(range(1, n_items + 1), n_recommendations, replace=False)\n",
    "        recommendations[user_id] = recommended_items\n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_recommendations_SVD_WPR(n_users, n_items, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg(true_ratings, recommendations, k):\n",
    "    ndcg_scores = []\n",
    "    for user_id, recommended_items in recommendations.items():\n",
    "        true_ratings_user = true_ratings.get(user_id, {})\n",
    "        sorted_true_ratings = sorted(true_ratings_user.items(), key=lambda x : x[1], reverse=True) # Sort by true ratings in descending order\n",
    "        true_ratings_user = [rating for item_id, rating in sorted_true_ratings[:k]] # Keep only the top-k true ratings\n",
    "        ideal_ranking = sorted(true_ratings_user, reverse=True)[:k]  # Keep only the top-k ideal ratings\n",
    "        ndcg = ndcg_score([true_ratings_user], [ideal_ranking], k=k)\n",
    "        ndcg_scores.append(ndcg)\n",
    "    return ndcg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ratings = {}\n",
    "for row in ratings_df.itertuples():\n",
    "    user_id = row.UserID\n",
    "    item_id = row.MovieID\n",
    "    rating = row.Rating\n",
    "    if user_id not in true_ratings:\n",
    "        true_ratings[user_id] = {}\n",
    "    true_ratings[user_id][item_id] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG scores for k=30:\n",
      "User 3522: 1.0000\n",
      "User 6: 1.0000\n",
      "User 4777: 1.0000\n",
      "User 3533: 1.0000\n",
      "User 3635: 1.0000\n",
      "User 4439: 1.0000\n",
      "User 4949: 1.0000\n",
      "User 5173: 1.0000\n",
      "User 4790: 1.0000\n",
      "User 2002: 1.0000\n",
      "User 1867: 1.0000\n",
      "User 6040: 1.0000\n",
      "User 5340: 1.0000\n",
      "User 153: 1.0000\n",
      "User 3392: 1.0000\n",
      "User 315: 1.0000\n",
      "User 3851: 1.0000\n",
      "User 4807: 1.0000\n",
      "User 3583: 1.0000\n",
      "User 3511: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# showing the scores for 20 random users\n",
    "random_user_ids = np.random.choice(range(1, n_users + 1), 20, replace=False)\n",
    "for k in k_values:\n",
    "    ndcg_scores = calculate_ndcg(true_ratings, recommendations, k)\n",
    "\n",
    "    # Print NDCG scores for the current k\n",
    "    print(f\"NDCG scores for k={k}:\")\n",
    "    for user_id in random_user_ids:\n",
    "        ndcg = ndcg_scores[random_user_ids.tolist().index(user_id)]\n",
    "        print(f\"User {user_id}: {ndcg:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision(true_ratings, recommendations, k):\n",
    "    average_precisions = []\n",
    "    for user_id, recommended_items in recommendations.items():\n",
    "        true_ratings_user = true_ratings.get(user_id, {})\n",
    "        relevant_items = [item_id for item_id, rating in true_ratings_user.items()]\n",
    "        if not relevant_items:\n",
    "            average_precisions.append(0.0)\n",
    "            continue\n",
    "\n",
    "        precision_at_k = []\n",
    "        num_relevant = 0\n",
    "        for i, recommended_item in enumerate(recommended_items[:k]):\n",
    "            if recommended_item in relevant_items:\n",
    "                num_relevant += 1\n",
    "                precision_at_k.append(num_relevant / (i + 1))\n",
    "\n",
    "        if not precision_at_k:\n",
    "            average_precisions.append(0.0)\n",
    "        else:\n",
    "            average_precision = sum(precision_at_k) / num_relevant\n",
    "            average_precisions.append(average_precision)\n",
    "\n",
    "    return average_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision scores for k=30:\n",
      "User 3522: 0.0000\n",
      "User 6: 0.0000\n",
      "User 4777: 0.0000\n",
      "User 3533: 0.0000\n",
      "User 3635: 0.0000\n",
      "User 4439: 0.0000\n",
      "User 4949: 0.0000\n",
      "User 5173: 0.0000\n",
      "User 4790: 0.0000\n",
      "User 2002: 0.0000\n",
      "User 1867: 0.0000\n",
      "User 6040: 0.0000\n",
      "User 5340: 0.0000\n",
      "User 153: 0.0000\n",
      "User 3392: 0.0000\n",
      "User 315: 0.0000\n",
      "User 3851: 0.0000\n",
      "User 4807: 0.2500\n",
      "User 3583: 0.0000\n",
      "User 3511: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in k_values:\n",
    "    average_precisions = calculate_average_precision(true_ratings, recommendations, k)\n",
    "\n",
    "    # Printing Average Precision scores for the current k\n",
    "    print(f\"Average Precision scores for k={k}:\")\n",
    "    for user_id in random_user_ids:\n",
    "        ap = average_precisions[random_user_ids.tolist().index(user_id)]\n",
    "        print(f\"User {user_id}: {ap:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting 5 users who have rated more than 100 movies\n",
    "users_with_hundred_ratings = user_item_matrix.sum(axis=1) > 100\n",
    "selected_users = random.sample([user_id for user_id, rated_movies_count in enumerate(users_with_hundred_ratings) if rated_movies_count], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieID\n",
       "1       4.146846\n",
       "2       3.201141\n",
       "3       3.016736\n",
       "4       2.729412\n",
       "5       3.006757\n",
       "          ...   \n",
       "3948    3.635731\n",
       "3949    4.115132\n",
       "3950    3.666667\n",
       "3951    3.900000\n",
       "3952    3.780928\n",
       "Name: Rating, Length: 3706, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the average rating for each movie\n",
    "average_rating = ratings_df.groupby('MovieID')['Rating'].mean()\n",
    "\n",
    "average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieID\n",
       "989     5.0\n",
       "3881    5.0\n",
       "1830    5.0\n",
       "3382    5.0\n",
       "787     5.0\n",
       "       ... \n",
       "826     1.0\n",
       "3228    1.0\n",
       "2845    1.0\n",
       "3209    1.0\n",
       "142     1.0\n",
       "Name: Rating, Length: 3706, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_movies = average_rating.sort_values(ascending=False)\n",
    "sorted_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rated_movies = sorted_movies.index.tolist()\n",
    "len(top_rated_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating recommendations for each user based on MovieAvg\n",
    "n_recommendation = 30\n",
    "recommendations_movieavg = {}\n",
    "for user_id in selected_users:\n",
    "    recommendations_movieavg[user_id] = top_rated_movies[:n_recommendation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 1660 (Movie Average):\n",
      "1. Schlafes Bruder (Brother of Sleep) (1995)\n",
      "2. Bittersweet Motel (2000)\n",
      "3. Follow the Bitch (1998)\n",
      "4. Song of Freedom (1936)\n",
      "5. Gate of Heavenly Peace, The (1995)\n",
      "6. Baby, The (1973)\n",
      "7. One Little Indian (1973)\n",
      "8. Smashing Time (1967)\n",
      "9. Ulysses (Ulisse) (1954)\n",
      "10. Lured (1947)\n",
      "11. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "12. Lamerica (1994)\n",
      "13. Apple, The (Sib) (1998)\n",
      "14. Sanjuro (1962)\n",
      "15. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "16. Shawshank Redemption, The (1994)\n",
      "17. Godfather, The (1972)\n",
      "18. Close Shave, A (1995)\n",
      "19. Usual Suspects, The (1995)\n",
      "20. Schindler's List (1993)\n",
      "21. Wrong Trousers, The (1993)\n",
      "22. Inheritors, The (Die Siebtelbauern) (1998)\n",
      "23. Callejón de los milagros, El (1995)\n",
      "24. Dry Cleaning (Nettoyage à sec) (1997)\n",
      "25. Dangerous Game (1993)\n",
      "26. Mamma Roma (1962)\n",
      "27. Bells, The (1926)\n",
      "28. Skipped Parts (2000)\n",
      "29. Hour of the Pig, The (1993)\n",
      "30. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "\n",
      "Recommendations for user 5815 (Movie Average):\n",
      "1. Schlafes Bruder (Brother of Sleep) (1995)\n",
      "2. Bittersweet Motel (2000)\n",
      "3. Follow the Bitch (1998)\n",
      "4. Song of Freedom (1936)\n",
      "5. Gate of Heavenly Peace, The (1995)\n",
      "6. Baby, The (1973)\n",
      "7. One Little Indian (1973)\n",
      "8. Smashing Time (1967)\n",
      "9. Ulysses (Ulisse) (1954)\n",
      "10. Lured (1947)\n",
      "11. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "12. Lamerica (1994)\n",
      "13. Apple, The (Sib) (1998)\n",
      "14. Sanjuro (1962)\n",
      "15. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "16. Shawshank Redemption, The (1994)\n",
      "17. Godfather, The (1972)\n",
      "18. Close Shave, A (1995)\n",
      "19. Usual Suspects, The (1995)\n",
      "20. Schindler's List (1993)\n",
      "21. Wrong Trousers, The (1993)\n",
      "22. Inheritors, The (Die Siebtelbauern) (1998)\n",
      "23. Callejón de los milagros, El (1995)\n",
      "24. Dry Cleaning (Nettoyage à sec) (1997)\n",
      "25. Dangerous Game (1993)\n",
      "26. Mamma Roma (1962)\n",
      "27. Bells, The (1926)\n",
      "28. Skipped Parts (2000)\n",
      "29. Hour of the Pig, The (1993)\n",
      "30. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "\n",
      "Recommendations for user 5923 (Movie Average):\n",
      "1. Schlafes Bruder (Brother of Sleep) (1995)\n",
      "2. Bittersweet Motel (2000)\n",
      "3. Follow the Bitch (1998)\n",
      "4. Song of Freedom (1936)\n",
      "5. Gate of Heavenly Peace, The (1995)\n",
      "6. Baby, The (1973)\n",
      "7. One Little Indian (1973)\n",
      "8. Smashing Time (1967)\n",
      "9. Ulysses (Ulisse) (1954)\n",
      "10. Lured (1947)\n",
      "11. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "12. Lamerica (1994)\n",
      "13. Apple, The (Sib) (1998)\n",
      "14. Sanjuro (1962)\n",
      "15. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "16. Shawshank Redemption, The (1994)\n",
      "17. Godfather, The (1972)\n",
      "18. Close Shave, A (1995)\n",
      "19. Usual Suspects, The (1995)\n",
      "20. Schindler's List (1993)\n",
      "21. Wrong Trousers, The (1993)\n",
      "22. Inheritors, The (Die Siebtelbauern) (1998)\n",
      "23. Callejón de los milagros, El (1995)\n",
      "24. Dry Cleaning (Nettoyage à sec) (1997)\n",
      "25. Dangerous Game (1993)\n",
      "26. Mamma Roma (1962)\n",
      "27. Bells, The (1926)\n",
      "28. Skipped Parts (2000)\n",
      "29. Hour of the Pig, The (1993)\n",
      "30. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "\n",
      "Recommendations for user 5250 (Movie Average):\n",
      "1. Schlafes Bruder (Brother of Sleep) (1995)\n",
      "2. Bittersweet Motel (2000)\n",
      "3. Follow the Bitch (1998)\n",
      "4. Song of Freedom (1936)\n",
      "5. Gate of Heavenly Peace, The (1995)\n",
      "6. Baby, The (1973)\n",
      "7. One Little Indian (1973)\n",
      "8. Smashing Time (1967)\n",
      "9. Ulysses (Ulisse) (1954)\n",
      "10. Lured (1947)\n",
      "11. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "12. Lamerica (1994)\n",
      "13. Apple, The (Sib) (1998)\n",
      "14. Sanjuro (1962)\n",
      "15. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "16. Shawshank Redemption, The (1994)\n",
      "17. Godfather, The (1972)\n",
      "18. Close Shave, A (1995)\n",
      "19. Usual Suspects, The (1995)\n",
      "20. Schindler's List (1993)\n",
      "21. Wrong Trousers, The (1993)\n",
      "22. Inheritors, The (Die Siebtelbauern) (1998)\n",
      "23. Callejón de los milagros, El (1995)\n",
      "24. Dry Cleaning (Nettoyage à sec) (1997)\n",
      "25. Dangerous Game (1993)\n",
      "26. Mamma Roma (1962)\n",
      "27. Bells, The (1926)\n",
      "28. Skipped Parts (2000)\n",
      "29. Hour of the Pig, The (1993)\n",
      "30. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "\n",
      "Recommendations for user 2375 (Movie Average):\n",
      "1. Schlafes Bruder (Brother of Sleep) (1995)\n",
      "2. Bittersweet Motel (2000)\n",
      "3. Follow the Bitch (1998)\n",
      "4. Song of Freedom (1936)\n",
      "5. Gate of Heavenly Peace, The (1995)\n",
      "6. Baby, The (1973)\n",
      "7. One Little Indian (1973)\n",
      "8. Smashing Time (1967)\n",
      "9. Ulysses (Ulisse) (1954)\n",
      "10. Lured (1947)\n",
      "11. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "12. Lamerica (1994)\n",
      "13. Apple, The (Sib) (1998)\n",
      "14. Sanjuro (1962)\n",
      "15. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "16. Shawshank Redemption, The (1994)\n",
      "17. Godfather, The (1972)\n",
      "18. Close Shave, A (1995)\n",
      "19. Usual Suspects, The (1995)\n",
      "20. Schindler's List (1993)\n",
      "21. Wrong Trousers, The (1993)\n",
      "22. Inheritors, The (Die Siebtelbauern) (1998)\n",
      "23. Callejón de los milagros, El (1995)\n",
      "24. Dry Cleaning (Nettoyage à sec) (1997)\n",
      "25. Dangerous Game (1993)\n",
      "26. Mamma Roma (1962)\n",
      "27. Bells, The (1926)\n",
      "28. Skipped Parts (2000)\n",
      "29. Hour of the Pig, The (1993)\n",
      "30. Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommendations for each selected users\n",
    "for user_id, recommended_movies in recommendations_movieavg.items():\n",
    "    print(f\"Recommendations for user {user_id} (Movie Average):\")\n",
    "    for i, movie_id in enumerate(recommended_movies, 1):\n",
    "        movie_title = movies_df[movies_df['MovieID'] == movie_id]['Title'].values[0]\n",
    "        print(f\"{i}. {movie_title}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth values \n",
    "ground_truth = {}\n",
    "for user_id in selected_users:\n",
    "    rated_movies = set(ratings_df[ratings_df['UserID'] == user_id]['MovieID'])\n",
    "    ground_truth[user_id] = [movie_id in rated_movies for movie_id in top_rated_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision Score: 0.0272\n",
      "Average NDCG Score: 0.0333\n"
     ]
    }
   ],
   "source": [
    "# initialising the lists to store AP score and ndcg score for\n",
    "ap_scores_movie_avg = []\n",
    "ndcg_scores_movie_avg = []\n",
    "\n",
    "# evaluating recommendations for all 30 users\n",
    "for user_id in selected_users:\n",
    "    is_relevant = ground_truth[user_id]\n",
    "    recommended_movies = [1 if movie_id in recommendations_movieavg[user_id] else 0 for movie_id in top_rated_movies]\n",
    "\n",
    "    # calculating AP\n",
    "    ap_movie_avg = average_precision_score(is_relevant, recommended_movies)\n",
    "    ap_scores_movie_avg.append(ap_movie_avg)\n",
    "\n",
    "    # calculating NDCG\n",
    "    true_ratings_user = [int(is_relevant[i]) for i in range(len(top_rated_movies))]\n",
    "    predicted_ratings = [recommended_movies[i] for i in range(len(top_rated_movies))]\n",
    "    ndcg_movie_avg = ndcg_score([true_ratings_user], [predicted_ratings], k=30)\n",
    "    ndcg_scores_movie_avg.append(ndcg_movie_avg)\n",
    "\n",
    "# calculating the average precision score and average NDCG scores\n",
    "average_ap_movie_avg = sum(ap_scores_movie_avg) / len(ap_scores_movie_avg)\n",
    "average_ndcg_movie_avg = sum(ndcg_scores_movie_avg) / len(ndcg_scores_movie_avg)\n",
    "\n",
    "print(f\"Average Precision Score: {average_ap_movie_avg:.4f}\")\n",
    "print(f\"Average NDCG Score: {average_ndcg_movie_avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
